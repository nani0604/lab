1.You are tasked with developing a velocity-based navigation algorithm for a differential wheeled
mobile robot. The robot should be able to navigate to a specified goal point in a 2D plane while
avoiding obstacles. The algorithm must incorporate the robot's kinematic model to control its
motion based on the velocity of the wheels.

code :

% Initial robot pose [x, y, theta] and goal [x, y]
robot_pose = [0, 0, 0]; % [x, y, theta]
goal = [10, 10]; % Goal position
dt = 0.1; % Time step

% Obstacles: [x, y] positions
obstacles = [3, 4; 5, 5; 8, 7];  % Add more obstacles as needed
safe_distance = 2.0;  % Safe distance to avoid obstacles
turn_angle_gain = 3;  % How aggressively to turn when near an obstacle
linear_velocity = 0.5; % Constant linear velocity

% Simulation setup
figure;
axis equal;
hold on;
plot(goal(1), goal(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); % Plot goal
plot(obstacles(:,1), obstacles(:,2), 'ko', 'MarkerSize', 10, 'LineWidth', 2); % Plot obstacles
xlim([-1 11]);
ylim([-1 11]);
xlabel('X Position');
ylabel('Y Position');
title('Velocity Based Navigation Algorithm');

% Main loop: robot moves towards the goal
while norm(robot_pose(1:2) - goal(1:2)) > 0.2
    % Goal attraction (desired movement direction)
    direction_to_goal = atan2(goal(2) - robot_pose(2), goal(1) - robot_pose(1));
    error_angle = direction_to_goal - robot_pose(3);
    
    % Control parameters
    angular_velocity = 2 * error_angle; % Angular velocity to adjust heading
    
    % Obstacle avoidance by adjusting the path before it's too close
    for i = 1:size(obstacles, 1)
        distance_to_obstacle = norm(robot_pose(1:2) - obstacles(i, :));
        if distance_to_obstacle < safe_distance
            % Calculate angle to the obstacle
            direction_to_obstacle = atan2(obstacles(i, 2) - robot_pose(2), obstacles(i, 1) - robot_pose(1));
            angle_diff = direction_to_obstacle - robot_pose(3);
            
            % If the robot is facing the obstacle directly, plan to turn
            if abs(angle_diff) < pi/4  % Facing the obstacle within a threshold
                if angle_diff > 0
                    angular_velocity = angular_velocity - turn_angle_gain;  % Turn left
                else
                    angular_velocity = angular_velocity + turn_angle_gain;  % Turn right
                end
            end
        end
    end
    
    % Update pose (motion model)
    robot_pose(3) = robot_pose(3) + angular_velocity * dt; % Update orientation (theta)
    robot_pose(1) = robot_pose(1) + linear_velocity * cos(robot_pose(3)) * dt; % Update x position
    robot_pose(2) = robot_pose(2) + linear_velocity * sin(robot_pose(3)) * dt; % Update y position
    
    % Plot the robot's position
    plot(robot_pose(1), robot_pose(2), 'bo', 'MarkerSize', 6, 'LineWidth', 2); % Plot current position
    drawnow;
    
    % Display velocities in the console
    fprintf('Linear Velocity: %.2f m/s, Angular Velocity: %.2f rad/s\n', linear_velocity, angular_velocity);
    
    % Pause to visualize in real-time
    pause(dt);
end

disp('Goal reached!');



2.You are tasked with developing a navigation algorithm for a differential wheeled mobile robot
using an Odometry-based motion model. The robot should navigate to a predefined goal
location, estimate its position using Odometry, and adjust its path accordingly. 


code:

% Robot Navigation to a Goal using Odometry-based Motion Model with Multiple Obstacle Avoidance

% Initialize the robot's pose: [x, y, theta]
robot_pose = [0, 0, 0]; % Starting at the origin facing right (0 radians)
goal = [10, 10]; % Goal position
dt = 0.1; % Time step
linear_velocity = 0.5; % Constant linear velocity

% Define multiple obstacles as a matrix where each row is an obstacle [x, y]
obstacles = [5, 5;   % Obstacle 1
             7, 8;   % Obstacle 2
             4, 3];  % Obstacle 3

% Define the radius of each obstacle
obstacle_radius = 0.5; % Radius of the obstacles

% Initialize the plot
figure;
hold on;
grid on;
xlim([-1, 12]); % Set x-axis limits
ylim([-1, 12]); % Set y-axis limits
title('Robot Navigation to Goal with Multiple Obstacle Avoidance');
xlabel('X Position');
ylabel('Y Position');
plot(goal(1), goal(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); % Plot the goal

% Plot all obstacles
for i = 1:size(obstacles, 1)
    plot(obstacles(i, 1), obstacles(i, 2), 'ko', 'MarkerSize', 10, 'LineWidth', 2); % Plot each obstacle
end

% Navigation loop
while norm(robot_pose(1:2) - goal(1:2)) > 0.2
    % Calculate the direction to the goal
    direction_to_goal = atan2(goal(2) - robot_pose(2), goal(1) - robot_pose(1));
    
    % Calculate the angle error
    error_angle = direction_to_goal - robot_pose(3);
    
    % Normalize the error angle to the range [-pi, pi]
    error_angle = atan2(sin(error_angle), cos(error_angle));
    
    % Initialize a variable to track whether an obstacle is detected
    obstacle_detected = false;

    % Check distances to all obstacles
    for i = 1:size(obstacles, 1)
        distance_to_obstacle = norm(robot_pose(1:2) - obstacles(i, :));
        
        % If the robot is close to an obstacle, adjust its path
        if distance_to_obstacle < obstacle_radius + 0.5 % 0.5 is the safety distance
            obstacle_detected = true; % Set flag
            % Calculate the avoidance direction
            avoidance_direction = atan2(robot_pose(2) - obstacles(i, 2), robot_pose(1) - obstacles(i, 1));
            % Adjust the error angle to steer away from the obstacle
            error_angle = error_angle + pi/4; % Turn 45 degrees away from the obstacle
        end
    end

    % Calculate the angular velocity
    angular_velocity = 2 * error_angle; % Proportional control for angular velocity

    % Update the robot's pose
    robot_pose(3) = robot_pose(3) + angular_velocity * dt; % Update theta
    robot_pose(1) = robot_pose(1) + linear_velocity * cos(robot_pose(3)) * dt; % Update x
    robot_pose(2) = robot_pose(2) + linear_velocity * sin(robot_pose(3)) * dt; % Update y

    % Plot the robot's current position
    plot(robot_pose(1), robot_pose(2), 'bo', 'MarkerSize', 5);
    pause(dt); % Pause for a moment to visualize the motion
end

disp('Goal reached!');
hold off; % Release the plot hold

3.You are tasked with developing a probabilistic range sensor model for a mobile robot navigating
in a known environment. The robot is equipped with a range sensor (e.g., LIDAR, sonar) that
measures the distance to nearby obstacles. The sensor model should account for noise and
uncertainty in the measurements and incorporate probabilistic principles. 

code:

% Parameters
true_distance = 10; % True distance to the obstacle (meters)
sensor_noise_mean = 0; % Mean of the sensor noise (meters)
sensor_noise_std = 0.5; % Standard deviation of the sensor noise (meters)
num_measurements = 100; % Number of measurements to simulate

% Preallocate array for measurements
measurements = zeros(1, num_measurements);

% Simulate measurements
for i = 1:num_measurements
    % Generate a noisy measurement
    noise = normrnd(sensor_noise_mean, sensor_noise_std); % Gaussian noise
    measurements(i) = true_distance + noise; % Noisy measurement
end

% Calculate mean and standard deviation of measurements
mean_measurement = mean(measurements);
std_measurement = std(measurements);

% Display results
fprintf('True Distance: %.2f m\n', true_distance);
fprintf('Mean Measurement: %.2f m\n', mean_measurement);
fprintf('Standard Deviation of Measurements: %.2f m\n', std_measurement);

% Plot the measurements
figure;
histogram(measurements, 'Normalization', 'pdf');
hold on;

% Plot Gaussian distribution based on mean and std
x = linspace(min(measurements), max(measurements), 100);
pdf = normpdf(x, mean_measurement, std_measurement);
plot(x, pdf, 'r-', 'LineWidth', 2);
xlabel('Distance (m)');
ylabel('Probability Density');
title('Histogram of Noisy Range Measurements');
legend('Measured Data', 'Gaussian Fit');
grid on;

4.You are tasked with developing an Extended Kalman Filter Simultaneous Localization and
Mapping (EKF-SLAM) algorithm for a mobile robot navigating in a 2D environment. The robot
must localize itself and map the surrounding environment simultaneously while dealing with
sensor noise and motion uncertainty. 

code:

clear; clc;
x = [0; 0; 0]; P = eye(3); % State [x, y, theta] and covariance
landmark = [0; -6];         % Known landmark position
Q = 0.01 * eye(3); R = 0.1 * eye(2); % Process and measurement noise
dt = 0.1; u = [1; 0.1];    % Control inputs (linear and angular velocity)
grid_limit = 10;           % Grid limit [-10, 10]

tic; % Start timer
figure; % Create a new figure for plotting
hold on;
axis([-10 10 -10 10]); % Set axis limits
xlabel('X Position');
ylabel('Y Position');
title('Robot Navigation with EKF-SLAM');
grid on;

while toc < 30  % Loop for 30 seconds
    % Predict step with boundary checks
    x_new = x + [u(1)*cos(x(3))*dt; u(1)*sin(x(3))*dt; u(2)*dt];
    x_new(1:2) = max(min(x_new(1:2), grid_limit), -grid_limit); % Keep inside grid
    x = x_new; 
    P = P + Q; % Update covariance (process noise)

    % Simulate measurement (range and bearing to the landmark)
    dx = landmark(1) - x(1); 
    dy = landmark(2) - x(2);
    z = [sqrt(dx^2 + dy^2); atan2(dy, dx)] + R * randn(2, 1); 

    % Update step
    H = [-dx/sqrt(dx^2+dy^2), -dy/sqrt(dx^2+dy^2), 0; 
          dy/(dx^2+dy^2), -dx/(dx^2+dy^2), -1];
    K = P * H' / (H * P * H' + R); % Kalman gain
    x = x + K * (z - [sqrt(dx^2+dy^2); atan2(dy, dx)]); 
    P = (eye(3) - K * H) * P; 

    % Plot robot and landmark
    plot(x(1), x(2), 'bo', 'MarkerFaceColor', 'b'); % Robot
    plot(landmark(1), landmark(2), 'rx', 'MarkerSize', 10, 'LineWidth', 2); % Landmark
    pause(0.1); 
end

5.You are tasked with developing a 2D representation of an indoor environment, such as a room
or office, that includes key building components like walls, doors, tables, and chairs. The 2D
map should be represented as a grid map or occupancy grid, and the environment must be
visualized clearly. The objective is to create an environment model that can later be used for
robot navigation or simulation purposes. 

code:

% Define grid size (10x10 grid)
gridSize = 10;

% Create a binary occupancy grid (0 = free space, 1 = occupied space)
environment = zeros(gridSize, gridSize);

% Add walls (set edges as walls)
environment(1, :) = 1; % Top wall
environment(end, :) = 1; % Bottom wall
environment(:, 1) = 1; % Left wall
environment(:, end) = 1; % Right wall

% Add a door on the bottom wall (at position 5)
environment(end, 5) = 0; % Free space for the door

% Add a small table (2x2 block)
environment(4:5, 4:5) = 1;

% Plot the occupancy grid
figure;
imagesc(environment);
colormap(gray); % Set color map to grayscale
colorbar; % Show color bar
axis equal; % Keep aspect ratio
title('Simple 2D Indoor Map'); % Title for the plot
xlabel('X-axis (Grid)'); % X-axis label
ylabel('Y-axis (Grid)'); % Y-axis label
grid on; % Show grid

6.You are tasked with developing an autonomous navigation system for a drone using Robot
Operating System (ROS) for simulation and MATLAB for control algorithm development. The
drone must navigate through a 3D environment while avoiding obstacles, following a defined
path, and reaching specified waypoints autonomously. The simulation should use ROS for
communication and visualization, while MATLAB is used to design the navigation and control
algorithms. 

code:

% Waypoints
waypoints = [0, 0; 5, 5; 10, 0]; % Example waypoints

% Initialize position and control
drone_pose = [0, 0]; % Starting position
dt = 0.1;
for i = 1:size(waypoints, 1)
goal = waypoints(i, :);
while norm(drone_pose - goal) > 0.1
% Calculate direction to goal
direction_to_goal = atan2(goal(2) - drone_pose(2), goal(1) - drone_pose(1));
drone_pose = drone_pose + [cos(direction_to_goal), sin(direction_to_goal)] * dt;

% Plot position
plot(drone_pose(1), drone_pose(2), 'bo');
hold on;
pause(0.1);
end
end
disp('Waypoints reached!');

7.You are tasked with developing an adaptive Monte Carlo Localization (AMCL) algorithm for a
wheeled robot operating in a known 2D environment. The robot must localize itself within a
map of the environment by using sensor data (e.g., laser rangefinder or LiDAR) and a motion
model. The goal is to implement the particle filter localization algorithm, where the number of
particles adapts based on the uncertainty of the robot's location, using MATLAB for control and
ROS for the simulation environment. 

code:

% Initialize particles for AMCL
num_particles = 500;
particles = [rand(num_particles, 1) * 10, rand(num_particles, 1) * 10, rand(num_particles, 1) * 2 * pi];
weights = ones(num_particles, 1) / num_particles;

% Main loop for particle filter
for t = 1:100
% Motion model update
for i = 1:num_particles
particles(i, 1) = particles(i, 1) + 0.1 * cos(particles(i, 3));
particles(i, 2) = particles(i, 2) + 0.1 * sin(particles(i, 3));
particles(i, 3) = particles(i, 3) + 0.05 * randn;
end

% Sensor model: Update weights based on sensor data
sensor_measurement = 5; % Example measurement
weights = exp(-(sensor_measurement - particles(:, 1)).^2 / 0.1);
weights = weights / sum(weights); % Normalize weights

% Resample particles
particles = particles(randsample(1:num_particles, num_particles, true, weights), :);

% Plot particles
plot(particles(:, 1), particles(:, 2), 'r.');
pause(0.1);
end

8.you are tasked with developing a LiDAR-based autonomous navigation algorithm for a wheeled
robot in a known 2D environment. The robot must navigate from an initial position to a goal
position while avoiding obstacles based on real-time LiDAR sensor data. The goal is to
implement the navigation algorithm using ROS for simulation and data handling, while
MATLAB is used to design the navigation and control algorithm. 

code:

% LiDAR-Based Autonomous Navigation
lidarSub = rossubscriber('/scan');
velPub = rospublisher('/cmd_vel', 'geometry_msgs/Twist');
velMsg = rosmessage(velPub);

% Robot parameters
goal = [5, 5];
robot_pose = [0, 0, 0];

while true
lidarData = receive(lidarSub);
ranges = lidarData.Ranges;
angles = linspace(lidarData.AngleMin, lidarData.AngleMax, numel(ranges));

obstacleIndices = find(ranges < 0.5);

if ~isempty(obstacleIndices)
steerDirection = mean(angles(obstacleIndices));
velMsg.Angular.Z = -steerDirection;
velMsg.Linear.X = 0;
else
direction_to_goal = atan2(goal(2) - robot_pose(2), goal(1) - robot_pose(1));
velMsg.Angular.Z = direction_to_goal - robot_pose(3);
velMsg.Linear.X = 0.5;
end

send(velPub, velMsg);
end








